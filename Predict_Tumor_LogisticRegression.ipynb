{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mPNBGCI7IRwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de365d3-d32a-42ed-d14d-7a7689ac1c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tumor sizes:\n",
            " [[3.78]\n",
            " [2.44]\n",
            " [2.09]\n",
            " [0.14]\n",
            " [1.72]\n",
            " [1.05]\n",
            " [4.92]\n",
            " [4.37]\n",
            " [4.96]\n",
            " [4.52]\n",
            " [3.69]\n",
            " [5.88]]\n",
            "Predicting Tumor for size 3.46:\n",
            "Malignant (YES)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "\n",
        "\n",
        "tumor_size = np.array([3.78, 2.44, 2.09, 0.14, 1.72, 1.05, 4.92, 4.37, 4.96, 4.52, 3.69, 5.88]).reshape(-1, 1)\n",
        "print(\"Tumor sizes:\\n\", tumor_size)\n",
        "\n",
        "# Target labels: 0 = benign, 1 = malignant\n",
        "labels = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "\n",
        "logr = linear_model.LogisticRegression()\n",
        "logr.fit(tumor_size, labels)\n",
        "\n",
        "# Predict for a new tumor size (3.46)\n",
        "new_tumor_size = np.array([3.46]).reshape(-1, 1)\n",
        "prediction = logr.predict(new_tumor_size)\n",
        "\n",
        "\n",
        "print(\"Predicting Tumor for size 3.46:\")\n",
        "if prediction[0] == 1:\n",
        "    print(\"Malignant (YES)\")\n",
        "else:\n",
        "    print(\"Benign (NO)\")\n"
      ]
    }
  ]
}